{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmWItLtP80+FGsOBRXDy4+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikhil11072003/NLP_Lab/blob/main/NLP_Exp3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemming **"
      ],
      "metadata": {
        "id": "2jgq042vHF5U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Porter stemmer"
      ],
      "metadata": {
        "id": "B0d-YKCMHNkT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYja5hAVGNPf",
        "outputId": "b10b6ad5-fc0b-4c3b-de20-116ef23505f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "porter = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def porter_stemmer(word):\n",
        "    def apply_rule(word, suffix, replacement, condition):\n",
        "        if condition(word):\n",
        "            stem = re.sub(suffix + \"$\", replacement, word)\n",
        "            return stem\n",
        "        return word\n",
        "\n",
        "    def step1a(word):\n",
        "        if word.endswith(\"sses\"):\n",
        "            return word[:-2]\n",
        "        elif word.endswith(\"ies\"):\n",
        "            return word[:-2]\n",
        "        elif word.endswith(\"ss\"):\n",
        "            return word\n",
        "        elif word.endswith(\"s\"):\n",
        "            return word[:-1]\n",
        "        return word\n",
        "\n",
        "    def step1b(word):\n",
        "        if word.endswith(\"eed\"):\n",
        "            if re.search(r\"eed$\", word) and len(word) > 4:\n",
        "                return word[:-1]\n",
        "        elif word.endswith(\"ed\"):\n",
        "            if re.search(r\"ed$\", word):\n",
        "                return apply_rule(word[:-2], \"ed\", \"\", lambda w: re.search(r\"[aeiouy]\", w))\n",
        "        elif word.endswith(\"ing\"):\n",
        "            if re.search(r\"ing$\", word):\n",
        "                return apply_rule(word[:-3], \"ing\", \"\", lambda w: re.search(r\"[aeiouy]\", w))\n",
        "        return word\n",
        "\n",
        "    def step1c(word):\n",
        "        if word.endswith(\"y\"):\n",
        "            if re.search(r\"y$\", word):\n",
        "                return apply_rule(word[:-1], \"y\", \"i\", lambda w: re.search(r\"[aeiouy]\", w))\n",
        "        return word\n",
        "\n",
        "    def step2(word):\n",
        "        if re.search(r\"(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti)$\", word):\n",
        "            return apply_rule(word, r\"(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti)$\", \"\", lambda w: re.search(r\"[aeiouy]\", w))\n",
        "        return word\n",
        "\n",
        "    def step3(word):\n",
        "        if re.search(r\"(icate|ative|alize|iciti|ical|ful|ness)$\", word):\n",
        "            return apply_rule(word, r\"(icate|ative|alize|iciti|ical|ful|ness)$\", \"\", lambda w: re.search(r\"[aeiouy]\", w))\n",
        "        return word\n",
        "\n",
        "    def step4(word):\n",
        "        if re.search(r\"(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ism|ate|iti|ous|ive|ize)$\", word):\n",
        "            return apply_rule(word, r\"(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ism|ate|iti|ous|ive|ize)$\", \"\", lambda w: len(w) > 1)\n",
        "        elif word.endswith(\"sion\") or word.endswith(\"tion\"):\n",
        "            return apply_rule(word, r\"(sion|tion)$\", \"\", lambda w: re.search(r\"[aeiouy]\", w))\n",
        "        return word\n",
        "\n",
        "    def step5a(word):\n",
        "        if re.search(r\"e$\", word):\n",
        "            return apply_rule(word[:-1], \"e\", \"\", lambda w: m(w) > 1 or (m(w) == 1 and not cvc(w[:-1])))\n",
        "        return word\n",
        "\n",
        "    def step5b(word):\n",
        "        if m(word) > 1 and re.search(r\"ll$\", word):\n",
        "            return word[:-1]\n",
        "        return word\n",
        "\n",
        "    def m(word):\n",
        "        return len(re.findall(r\"[aeiouy]+\", word))\n",
        "\n",
        "    def cvc(word):\n",
        "        return re.search(r\"[aeiouy][^aeiouy][aeiouy]$\", word) and not re.search(r\"[wxy]$\", word)\n",
        "\n",
        "    word = word.lower()\n",
        "    word = step1a(word)\n",
        "    word = step1b(word)\n",
        "    word = step1c(word)\n",
        "    word = step2(word)\n",
        "    word = step3(word)\n",
        "    word = step4(word)\n",
        "    word = step5a(word)\n",
        "    word = step5b(word)\n",
        "\n",
        "    return word"
      ],
      "metadata": {
        "id": "lxWQs4sQGbPs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "words = [\"ruined\", \"filler\", \"studies\", \"happier\", \"agreement\", \"saying\", \"strange\"]\n",
        "for word in words:\n",
        "    print(f\"{word}: {porter_stemmer(word)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDlA_4QdG0CK",
        "outputId": "a721c6b5-0fdf-496d-8427-b1cb503ec3bf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ruined: ruin\n",
            "filler: fill\n",
            "studies: studi\n",
            "happier: happi\n",
            "agreement: agr\n",
            "saying: sa\n",
            "strange: strang\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Porter stemmer\n",
        "for word in words:\n",
        "    stemmed_word = porter.stem(word)\n",
        "    print(f\"{word}: {stemmed_word}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayKcPIgfG0Fx",
        "outputId": "2671ff86-3755-4b43-f924-242bfb75710a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ruined: ruin\n",
            "filler: filler\n",
            "studies: studi\n",
            "happier: happier\n",
            "agreement: agreement\n",
            "saying: say\n",
            "strange: strang\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nl6RSQ5SG81i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}